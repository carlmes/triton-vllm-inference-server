# triton-vllm-inference-server
Container project for NVIDIA Triton using vLLM backend
